{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rcarrata/deeplearning_tf_examples/blob/master/1_Neural_Network_StepByStep.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# THEORY 1 - WARMING UP ####\n",
        "\n",
        "**Classification**: given data and true labels or  categories for each data point, train a model that predicts for each data example what its label should be.\n",
        "\n",
        "**Regression**: given data and true continuous value for each data point, train a model that can predict values for each data example.\n"
      ],
      "metadata": {
        "id": "HZFrb5Bnwb1n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Exercise 0 - LOADING DATASET\n",
        "\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!ls \"/content/drive/My Drive/Colab/Insurance/insurance.csv\"\n",
        "\n",
        "root_folder = \"/content/drive/My Drive/Colab/\"\n",
        "project_folder = \"Insurance/\"\n",
        "csv_file = \"insurance.csv\"\n",
        "\n",
        "csv_data = root_folder + project_folder + csv_file\n",
        "print(csv_data)\n",
        "\n",
        "dataset = pd.read_csv(csv_data)\n",
        "\n",
        "from google.colab.data_table import DataTable\n",
        "DataTable.max_columns = 60\n",
        "\n",
        "dataset.head()"
      ],
      "metadata": {
        "id": "vTlOkhmUn5kO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "outputId": "c14a9c9d-60c9-4a29-9f1c-a2c0cd420225"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "'/content/drive/My Drive/Colab/Insurance/insurance.csv'\n",
            "/content/drive/My Drive/Colab/Insurance/insurance.csv\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   age     sex     bmi  children smoker     region      charges\n",
              "0   19  female  27.900         0    yes  southwest  16884.92400\n",
              "1   18    male  33.770         1     no  southeast   1725.55230\n",
              "2   28    male  33.000         3     no  southeast   4449.46200\n",
              "3   33    male  22.705         0     no  northwest  21984.47061\n",
              "4   32    male  28.880         0     no  northwest   3866.85520"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-47512e92-5a4f-4355-aa36-32b1793b89cc\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>bmi</th>\n",
              "      <th>children</th>\n",
              "      <th>smoker</th>\n",
              "      <th>region</th>\n",
              "      <th>charges</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19</td>\n",
              "      <td>female</td>\n",
              "      <td>27.900</td>\n",
              "      <td>0</td>\n",
              "      <td>yes</td>\n",
              "      <td>southwest</td>\n",
              "      <td>16884.92400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>18</td>\n",
              "      <td>male</td>\n",
              "      <td>33.770</td>\n",
              "      <td>1</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>1725.55230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>28</td>\n",
              "      <td>male</td>\n",
              "      <td>33.000</td>\n",
              "      <td>3</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>4449.46200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>33</td>\n",
              "      <td>male</td>\n",
              "      <td>22.705</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>21984.47061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>32</td>\n",
              "      <td>male</td>\n",
              "      <td>28.880</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>3866.85520</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-47512e92-5a4f-4355-aa36-32b1793b89cc')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-47512e92-5a4f-4355-aa36-32b1793b89cc button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-47512e92-5a4f-4355-aa36-32b1793b89cc');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#### EXERCISE 1 - WARMING UP ####\n",
        "\n",
        "## Indexing just the rows. With a scalar integer.\n",
        "# Choose first 7 columns as features\n",
        "# Dataframe slicing using iloc\n",
        "features = dataset.iloc[:,0:6]\n",
        "\n",
        "# Choose the final column for prediction \n",
        "# We select the last column with -1 \n",
        "labels = dataset.iloc[:,-1] \n",
        "\n",
        "# features.shape[]\n",
        "# The pandas shape property tells us the shape of our data \n",
        "# — a vector of two values: the number of samples and the number of features.\n",
        "\n",
        "# Print the number of features in the dataset\n",
        "print(\"Number of features: \", features.shape[1])\n",
        "# Print the number of samples in the dataset\n",
        "print(\"Number of samples: \", features.shape[0])\n",
        "\n",
        "# See useful summary statistics for numeric features\n",
        "print(\"\\n\")\n",
        "print(\"## Describe features\")\n",
        "print(features.describe())\n",
        "\n",
        "# features.describe() -> Descriptive statistics include those that summarize \n",
        "# the central tendency, dispersion and shape of a dataset's distribution\n",
        "\n",
        "# Print the number of samples of the labels Series.\n",
        "print(labels.shape[0])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_ggP9Y_vE2G",
        "outputId": "419e85f1-8152-4f05-ab1d-e0daaeae8437"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of features:  6\n",
            "Number of samples:  1338\n",
            "\n",
            "\n",
            "## Describe features\n",
            "               age          bmi     children\n",
            "count  1338.000000  1338.000000  1338.000000\n",
            "mean     39.207025    30.663397     1.094918\n",
            "std      14.049960     6.098187     1.205493\n",
            "min      18.000000    15.960000     0.000000\n",
            "25%      27.000000    26.296250     0.000000\n",
            "50%      39.000000    30.400000     1.000000\n",
            "75%      51.000000    34.693750     2.000000\n",
            "max      64.000000    53.130000     5.000000\n",
            "1338\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "opIaIYLZ5QdT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# THEORY 2 - DATA PREPROCESSING ####\n",
        "\n",
        "### **Data preprocessing**: one-hot encoding and standardization\n",
        "\n",
        "* **One-hot encoding** of categorical features:\n",
        "\n",
        " *Since neural networks cannot work with string data directly, we need to convert our categorical features (“region”) into numerical*. \n",
        "\n",
        " One-hot encoding **creates a binary column for each category**.\n",
        "\n",
        "```python\n",
        "features  = pd.get_dummies(features)\n",
        "```\n",
        "\n",
        "Example: https://interactivechaos.com/es/manual/tutorial-de-machine-learning/la-funcion-getdummies\n",
        "\n",
        "### Split data into train and test sets:\n",
        "\n",
        "```python\n",
        "from sklearn.model_selection import train_test_split\n",
        "features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size=0.33, random_state=42)\n",
        "```\n",
        "\n",
        "### Standardize/normalize numerical features:\n",
        "\n",
        "* The usual **preprocessing** step for numerical variables, among others, is standardization that rescales features to zero mean and unit variance.\n",
        "\n",
        "* **Normalization** is another way of preprocessing numerical data: it scales the numerical features to a fixed range - usually between 0 and 1. \n",
        "\n",
        "To normalize the numerical features we use an exciting addition to scikit-learn, ColumnTransformer, in the following way:\n",
        "\n",
        "```python\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import Normalizer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "  \n",
        "ct = ColumnTransformer([('normalize', Normalizer(), ['age', 'bmi', 'children'])], remainder='passthrough')\n",
        "features_train = ct.fit_transform(features_train)\n",
        "features_test = ct.transform(features_test)\n",
        "```\n",
        "\n",
        "The name of the column transformer is “only numeric”, it applies a Normalizer() to the ‘age’, ‘bmi’, and ‘children’ columns, and for the rest of the columns it just passes through. ColumnTransformer() returns NumPy arrays and we convert them back to a pandas DataFrame so we can see some useful summaries of the scaled data.\n",
        "\n",
        "* To convert a NumPy array back into a pandas DataFrame, we can do:\n",
        "\n",
        "```python\n",
        "features_train_norm = pd.DataFrame(features_train_norm, columns = features_train.columns)\n",
        "```"
      ],
      "metadata": {
        "id": "JRRKoT0Nw0nm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#### EXERCISE 2 - DATA PRE-PROCESSING ####\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import Normalizer\n",
        "\n",
        "## Load the dataset\n",
        "# dataset = pd.read_csv('insurance.csv') # Dataset loaded in early step\n",
        "\n",
        "# Choose first 7 columns as features\n",
        "features = dataset.iloc[:,0:6] \n",
        "\n",
        "# Choose the final column for prediction\n",
        "labels = dataset.iloc[:,-1] \n",
        "\n",
        "# One-hot encoding for categorical variables\n",
        "# Convert categorical variable into dummy/indicator variables.\n",
        "# The get_dummies function allows you to eliminate the first of the columns \n",
        "# generated for each coded feature to avoid the so-called collinearity \n",
        "# (that one of the features is a linear combination of the others), \n",
        "# which makes it difficult for the algorithms to work correctly. \n",
        "# For this we have the drop_first argument.\n",
        "features = pd.get_dummies(features) \n",
        "\n",
        "# Split the data into training and test data\n",
        "features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size=0.33, random_state=42) \n",
        " \n",
        "# Normalize the numeric columns using ColumnTransformer\n",
        "ct = ColumnTransformer([('normalize', Normalizer(), ['age', 'bmi', 'children'])], remainder='passthrough')\n",
        "\n",
        "# Fit the normalizer to the training data and convert from numpy arrays to pandas frame\n",
        "features_train_norm = ct.fit_transform(features_train) \n",
        "\n",
        "# Applied the trained normalizer on the test data and convert from numpy arrays to pandas frame\n",
        "features_test_norm = ct.transform(features_test) \n",
        "\n",
        "# ColumnTransformer returns numpy arrays. Convert the features to dataframes\n",
        "features_train_norm = pd.DataFrame(features_train_norm, columns = features_train.columns)\n",
        "features_test_norm = pd.DataFrame(features_test_norm, columns = features_test.columns)\n",
        "\n",
        "my_ct = ColumnTransformer([('scale', StandardScaler(), ['age', 'bmi', 'children'])], remainder='passthrough')\n",
        "\n",
        "# Use the .fit_transform() method of my_ct to fit the column transformer to the \n",
        "# features_train DataFrame and at the same time transform it. Assign the result \n",
        "# to a variable called features_train_scale.\n",
        "features_train_scale = my_ct.fit_transform(features_train)\n",
        "\n",
        "# Use the .transform() method to transform the trained column transformer my_ct \n",
        "# to the features_test DataFrame. Assign the result to a variable called features_test_scale.\n",
        "features_test_scale = my_ct.transform(features_test)\n",
        "\n",
        "# Transform the features_train_scale NumPy array back to a DataFrame using \n",
        "# pd.DataFrame() and assign the result back to a variable called features_train_scale. \n",
        "# For the columns attribute use the .columns property of features_train.\n",
        "features_train_scale = pd.DataFrame(features_train_scale, columns = features_train.columns)\n",
        "\n",
        "# Transform the features_test_scale NumPy array back to DataFrame using \n",
        "# pd.DataFrame() and assign the result back to a variable called features_test_scale. \n",
        "# For the columns attribute use the .columns property of features_test.\n",
        "features_test_scale = pd.DataFrame(features_test_scale, columns = features_test.columns)\n",
        "\n",
        "# Print the statistics summary of the resulting train and test DataFrames, \n",
        "# features_train_scale and features_test_scale.\n",
        "# Observe the statistics of the numeric columns (mean, variance).\n",
        "\n",
        "print(\"## features_train_scale\\n\")\n",
        "print(features_train_scale.describe())\n",
        "\n",
        "print(\"\\n\")\n",
        "print(\"## features_test_scale\")\n",
        "print(features_test_scale.describe())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "su6TgJidNWzo",
        "outputId": "673f2f5e-c990-45eb-a11e-838f214cc342"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "## features_train_scale\n",
            "\n",
            "                age           bmi      children  sex_female    sex_male  \\\n",
            "count  8.960000e+02  8.960000e+02  8.960000e+02  896.000000  896.000000   \n",
            "mean   9.417070e-18  6.835275e-16 -1.069333e-16    0.487723    0.512277   \n",
            "std    1.000559e+00  1.000559e+00  1.000559e+00    0.500128    0.500128   \n",
            "min   -1.494934e+00 -2.438281e+00 -9.126072e-01    0.000000    0.000000   \n",
            "25%   -8.613199e-01 -7.139833e-01 -9.126072e-01    0.000000    0.000000   \n",
            "50%   -1.650038e-02 -5.227104e-02 -8.245892e-02    0.000000    1.000000   \n",
            "75%    8.987207e-01  6.598116e-01  7.476894e-01    1.000000    1.000000   \n",
            "max    1.743540e+00  3.776715e+00  3.238134e+00    1.000000    1.000000   \n",
            "\n",
            "        smoker_no  smoker_yes  region_northeast  region_northwest  \\\n",
            "count  896.000000  896.000000        896.000000        896.000000   \n",
            "mean     0.790179    0.209821          0.256696          0.252232   \n",
            "std      0.407408    0.407408          0.437054          0.434536   \n",
            "min      0.000000    0.000000          0.000000          0.000000   \n",
            "25%      1.000000    0.000000          0.000000          0.000000   \n",
            "50%      1.000000    0.000000          0.000000          0.000000   \n",
            "75%      1.000000    0.000000          1.000000          1.000000   \n",
            "max      1.000000    1.000000          1.000000          1.000000   \n",
            "\n",
            "       region_southeast  region_southwest  \n",
            "count        896.000000        896.000000  \n",
            "mean           0.255580          0.235491  \n",
            "std            0.436431          0.424542  \n",
            "min            0.000000          0.000000  \n",
            "25%            0.000000          0.000000  \n",
            "50%            0.000000          0.000000  \n",
            "75%            1.000000          0.000000  \n",
            "max            1.000000          1.000000  \n",
            "\n",
            "\n",
            "## features_test_scale\n",
            "              age         bmi    children  sex_female    sex_male   smoker_no  \\\n",
            "count  442.000000  442.000000  442.000000  442.000000  442.000000  442.000000   \n",
            "mean    -0.005829    0.061133   -0.011089    0.509050    0.490950    0.805430   \n",
            "std      0.966688    1.057251    1.002194    0.500485    0.500485    0.396318   \n",
            "min     -1.494934   -2.295321   -0.912607    0.000000    0.000000    0.000000   \n",
            "25%     -0.931721   -0.706877   -0.912607    0.000000    0.000000    1.000000   \n",
            "50%     -0.016500    0.007923   -0.082459    1.000000    0.000000    1.000000   \n",
            "75%      0.810719    0.774556    0.747689    1.000000    1.000000    1.000000   \n",
            "max      1.743540    3.684752    3.238134    1.000000    1.000000    1.000000   \n",
            "\n",
            "       smoker_yes  region_northeast  region_northwest  region_southeast  \\\n",
            "count  442.000000         442.00000        442.000000        442.000000   \n",
            "mean     0.194570           0.21267          0.223982          0.305430   \n",
            "std      0.396318           0.40966          0.417382          0.461111   \n",
            "min      0.000000           0.00000          0.000000          0.000000   \n",
            "25%      0.000000           0.00000          0.000000          0.000000   \n",
            "50%      0.000000           0.00000          0.000000          0.000000   \n",
            "75%      0.000000           0.00000          0.000000          1.000000   \n",
            "max      1.000000           1.00000          1.000000          1.000000   \n",
            "\n",
            "       region_southwest  \n",
            "count        442.000000  \n",
            "mean           0.257919  \n",
            "std            0.437985  \n",
            "min            0.000000  \n",
            "25%            0.000000  \n",
            "50%            0.000000  \n",
            "75%            1.000000  \n",
            "max            1.000000  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# THEORY 3 - NEURAL NETWORK MODEL BASICS ####\n",
        "\n",
        "## Neural network model: tf.keras.Sequential\n",
        "\n",
        "Now that we have our data preprocessed we can start building the neural network model. The most frequently used model in TensorFlow is Keras Sequential.\n",
        "\n",
        "* A **sequential model**, as the name suggests, **allows us to create models \n",
        "layer-by-layer in a step-by-step fashion**. This model can have only one input tensor and only one output tensor.\n",
        "\n",
        "* To design a sequential model, we first need to import Sequential from keras.models:\n",
        "\n",
        "```python\n",
        "from tensorflow.keras.models import Sequential\n",
        "```\n",
        "\n",
        "* To improve readability, we will design the model in a separate Python function called design_model(). The following command initializes a Sequential model instance my_model:\n",
        "\n",
        "```python\n",
        "my_model = Sequential(name=\"my first model\")\n",
        "```\n",
        "\n",
        "NOTE: name is an optional argument to any model in Keras.\n",
        "\n",
        "* Finally, we invoke our function in the main program with:\n",
        "\n",
        "```python\n",
        "my_model = design_model(features_train)\n",
        "```\n",
        "\n",
        "* The model’s layers are accessed via the layers attribute:\n",
        "\n",
        "```python\n",
        "print(my_model.layers)\n",
        "```\n",
        "\n",
        "As expected, the list of layers is empty. In the next exercise, we will start adding layers to our model.\n"
      ],
      "metadata": {
        "id": "ui4SBHARyAHU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#### EXERCISE 3 - NEURAL NETWORK MODEL BASICS ####\n",
        "#### Neural network model: tf.keras.Sequential Exercise\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# initialize an instance of Sequential() and assign it to a variable called model\n",
        "def design_model(features):\n",
        "  model = Sequential(name=\"my first model\")\n",
        "  return model\n",
        "  \n",
        "# dataset = pd.read_csv('insurance.csv') #load the dataset\n",
        "features = dataset.iloc[:,0:6] #choose first 7 columns as features\n",
        "labels = dataset.iloc[:,-1] #choose the final column for prediction\n",
        "\n",
        "features = pd.get_dummies(features) #one-hot encoding for categorical variables\n",
        "\n",
        "# split the data into training and test data\n",
        "features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size=0.33, random_state=42) \n",
        " \n",
        "# standardize\n",
        "ct = ColumnTransformer([('standardize', StandardScaler(), ['age', 'bmi', 'children'])], remainder='passthrough')\n",
        "\n",
        "# ct.fit_transform => Fit all transformers, transform the data and concatenate results.\n",
        "# ct.transform => Transform X separately by each transformer, concatenate results.\n",
        "features_train = ct.fit_transform(features_train)\n",
        "features_test = ct.transform(features_test)\n",
        "\n",
        "# Invoke the function for our model design\n",
        "model = design_model(features_train)\n",
        "\n",
        "# In the main program, using the layers attribute, print the layers of the model instance model.\n",
        "print(model.layers)\n",
        "\n",
        "# As expected, the list of layers is empty. In the next exercise, we will start adding layers to our model."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "quCYSobhUDrF",
        "outputId": "001e2e6b-082f-4305-88a0-fe221586c2ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#### THEORY 4 - NEURAL NETWORK MODEL - LAYERS ####\n",
        "\n",
        "###### Neural network model: layers - \n",
        "# Layers are the building blocks of neural networks and can contain 1 or more \n",
        "# neurons. \n",
        "\n",
        "#### !!! Each layer is associated with parameters: weights, and bias !!\n",
        "# that are tuned during the learning. A fully-connected layer in which all neurons connect \n",
        "# to all neurons in the next layer is created the following way in \n",
        "\n",
        "# PARAMETERS: weights, and bias\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# we chose 3 neurons here\n",
        "layer = layers.Dense(3)\n",
        "\n",
        "# Pay attention to the dimensions of the weight and bias parameter matrices. \n",
        "# Since we chose to create a layer with three neurons, the number of outputs of \n",
        "# this layer is 3. Hence, the bias parameter would be a vector of (3, 1) dimensions.\n",
        "print(layer.weights)\n",
        "\n",
        "# 13388 samples, 11 features as in our dataset\n",
        "input = tf.ones((1338, 11))\n",
        "# tf.ones => Creates a tensor with all elements set to one (1).\n",
        "\n",
        "# a fully-connected layer with 3 neurons\n",
        "layer = layers.Dense(3) \n",
        "\n",
        "# calculate the outputs\n",
        "output = layer(input) \n",
        "\n",
        "# print the weights\n",
        "print(layer.weights)\n",
        "\n",
        "# we get that the weight matrix has shape = (11, 3) and the bias matrix has \n",
        "# shape=(3,). Compare these weights with the diagram above to make sure you \n",
        "# can associate the resulting shapes to it.\n",
        "\n",
        "# Fortunately, we don’t have to worry about this. \n",
        "# TensorFlow will determine the shapes of the weight matrix and bias matrix \n",
        "# automatically the moment it encounters the first input.\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_W3RVk4OWMiO",
        "outputId": "a84951a3-1c36-4b1b-fecc-de2ca922d2ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[]\n",
            "[<tf.Variable 'dense_1/kernel:0' shape=(11, 3) dtype=float32, numpy=\n",
            "array([[ 0.32592195,  0.31091326,  0.44234145],\n",
            "       [-0.5610312 , -0.29185963,  0.42624545],\n",
            "       [ 0.45342636,  0.6380725 , -0.07350582],\n",
            "       [-0.31981993, -0.02801275,  0.62853265],\n",
            "       [ 0.15368855, -0.24774379, -0.14063168],\n",
            "       [-0.5377222 , -0.10184151, -0.42027795],\n",
            "       [-0.34179795,  0.4084469 ,  0.2444675 ],\n",
            "       [-0.45660064, -0.5320892 , -0.12887317],\n",
            "       [-0.61708075, -0.31729406, -0.48610944],\n",
            "       [-0.5544605 , -0.21437901, -0.33785877],\n",
            "       [ 0.5529678 , -0.26492321, -0.22141564]], dtype=float32)>, <tf.Variable 'dense_1/bias:0' shape=(3,) dtype=float32, numpy=array([0., 0., 0.], dtype=float32)>]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#### EXERCISE 4 - NEURAL NETWORK MODEL - LAYERS ####\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# 3 is the number we chose\n",
        "layer = layers.Dense(3) \n",
        "\n",
        "# we get empty weight and bias arrays because tensorflow \n",
        "# doesn't know what the shape is of the input to this layer\n",
        "print(layer.weights) \n",
        "\n",
        "# Change the number of samples in the input tensor from 1338 to 5000.\n",
        "#### tf.ones => Creates a tensor with all elements set to one (1).\n",
        "###### 5000 samples, 21 features\n",
        "input = tf.ones((5000, 21))\n",
        "\n",
        "# a fully-connected layer with 10 neurons\n",
        "\n",
        "#### Dense => implements Just your regular densely-connected NN layer.\n",
        "## Dense implements the operation:\n",
        "## output = activation(dot(input, kernel) + bias)\n",
        "## where activation is the element-wise activation function\n",
        "## passed as the activation argument, kernel is a weights matrix\n",
        "## created by the layer, and bias is a bias vector created by the layer\n",
        "## (only applicable if use_bias is True). These are all attributes of Dense.\n",
        "layer = layers.Dense(10) \n",
        "\n",
        "# calculate the outputs\n",
        "output = layer(input)\n",
        "\n",
        "# print the weights\n",
        "print(layer.weights)\n",
        "\n",
        "## we get that the weight matrix has shape = (11, 3) and the bias matrix has shape=(3,).\n",
        "## Compare these weights with the diagram above to make sure you can associate \n",
        "## the resulting shapes to it.\n",
        "\n",
        "## Fortunately, we don’t have to worry about this. TensorFlow will \n",
        "## determine the shapes of the weight matrix and bias matrix automatically \n",
        "## the moment it encounters the first input."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hmtgsvFp1xzw",
        "outputId": "b0d378cc-c86b-4250-af33-ff8d3aac0d90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[]\n",
            "[<tf.Variable 'dense_3/kernel:0' shape=(21, 10) dtype=float32, numpy=\n",
            "array([[-0.2790981 ,  0.12694335, -0.42396972, -0.25296703, -0.22709335,\n",
            "        -0.43407306, -0.00993699, -0.36362052,  0.05261731, -0.33542633],\n",
            "       [ 0.3547274 , -0.19319305, -0.25650918,  0.06288075, -0.0245699 ,\n",
            "         0.04370227,  0.10043794, -0.43751943, -0.3696518 ,  0.02677017],\n",
            "       [-0.2283514 ,  0.24852931,  0.32857513,  0.3089441 ,  0.32831532,\n",
            "        -0.3924433 ,  0.09203118, -0.01002866,  0.06180149, -0.18082145],\n",
            "       [ 0.36311412, -0.06443456,  0.15578699, -0.24180126,  0.3103785 ,\n",
            "        -0.27212167, -0.34078792,  0.18396866, -0.34347448, -0.34802   ],\n",
            "       [ 0.08576816, -0.3811952 , -0.06821838,  0.11085957, -0.21277793,\n",
            "         0.1770981 ,  0.34906322, -0.34313777, -0.13162178,  0.07922721],\n",
            "       [ 0.4193967 ,  0.11826366,  0.43793678, -0.33148384,  0.3668936 ,\n",
            "        -0.17717412, -0.39358744, -0.4258464 , -0.05565211, -0.38142458],\n",
            "       [ 0.34537584,  0.260648  , -0.15222472,  0.1060462 ,  0.357305  ,\n",
            "        -0.28806508, -0.25735188,  0.01614365,  0.20065778,  0.07085919],\n",
            "       [ 0.16176713, -0.23741789, -0.05873841,  0.36467665, -0.11781162,\n",
            "         0.36060292, -0.3334437 , -0.30016488, -0.01290065, -0.09651607],\n",
            "       [-0.34963697, -0.04806468, -0.27311203, -0.28938198,  0.30688614,\n",
            "         0.15832406, -0.42840323,  0.29966962,  0.07539916, -0.0389024 ],\n",
            "       [-0.00596154,  0.24278563, -0.16030094, -0.4252994 ,  0.10971701,\n",
            "         0.20097369,  0.05205375,  0.0742932 , -0.2557636 , -0.39795694],\n",
            "       [ 0.37311667, -0.02747545, -0.12737644,  0.00476328,  0.00105938,\n",
            "        -0.04739568, -0.27924654, -0.09060237,  0.10852057,  0.39576608],\n",
            "       [ 0.14798802, -0.08198541, -0.10965985,  0.3574577 , -0.13384712,\n",
            "         0.04497522,  0.21835202, -0.21287045, -0.18969864,  0.17992026],\n",
            "       [ 0.27128893, -0.09111056,  0.07304603, -0.27435982, -0.3348031 ,\n",
            "         0.40874147,  0.419662  , -0.38384944, -0.18480593, -0.1706082 ],\n",
            "       [ 0.12581211,  0.38200355, -0.2660737 , -0.08286262,  0.00116113,\n",
            "         0.14263988,  0.2249453 ,  0.38491553, -0.13802302, -0.41630697],\n",
            "       [-0.30393255,  0.39226276,  0.39137256, -0.0045754 , -0.07830387,\n",
            "         0.21439219,  0.27591383, -0.05265823, -0.1196878 ,  0.0317187 ],\n",
            "       [-0.08799919,  0.1501615 ,  0.30711585,  0.04739085,  0.30726355,\n",
            "        -0.13123557, -0.22889306, -0.0043608 , -0.36595014,  0.04955903],\n",
            "       [ 0.43376154, -0.13045916, -0.13095403,  0.13408   ,  0.41860783,\n",
            "        -0.338808  , -0.33529502, -0.03798419, -0.30786812, -0.3021366 ],\n",
            "       [-0.00468943, -0.05979359, -0.32742375,  0.38864928, -0.36033326,\n",
            "         0.20657969, -0.2906158 , -0.38635966, -0.02014762,  0.07740885],\n",
            "       [ 0.19632518,  0.0561389 ,  0.16596985, -0.1043669 , -0.38649318,\n",
            "        -0.09071419,  0.34576076, -0.15693513, -0.04811534, -0.3480199 ],\n",
            "       [ 0.20890665,  0.35003775,  0.26292467,  0.19841892, -0.25210673,\n",
            "         0.26862144, -0.2033653 , -0.38417605, -0.33067995,  0.00955674],\n",
            "       [ 0.15875202, -0.15014476, -0.20778495,  0.43528277, -0.15111017,\n",
            "         0.01935726,  0.07554978, -0.13862854, -0.16258484, -0.38715294]],\n",
            "      dtype=float32)>, <tf.Variable 'dense_3/bias:0' shape=(10,) dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# THEORY 5 - Neural network model - Input Layer ####\n",
        "\n",
        "## Neural network model: input layer Example\n",
        "\n",
        "* Inputs to a neural network are usually not considered the actual transformative layers. They are merely placeholders for data. \n",
        "\n",
        "* In Keras, an input for a neural network can be specified with a tf.keras.layers.InputLayer object. \n",
        "\n",
        "* The following code initializes an input layer for a DataFrame my_data that has 15 columns:\n",
        "\n",
        "```python\n",
        "from tensorflow.keras.layers import InputLayer\n",
        "my_input = InputLayer(input_shape=(15,))\n",
        "```\n",
        "\n",
        "* **IMPORTANT**: Notice that the input_shape parameter has to have its first dimension equal to the number of features in the data. You don’t need to specify the second dimension: the number of samples or batch size.\n",
        "\n",
        "* The following code avoids hard-coding with using the .shape property of the my_data DataFrame:\n",
        "\n",
        "```python\n",
        "#get the number of features/dimensions in the data\n",
        "num_features = my_data.shape[1] \n",
        "\n",
        "# without hard-coding\n",
        "my_input = tf.keras.layers.InputLayer(input_shape=(num_features,)) \n",
        "```\n",
        "\n",
        "* The following code adds this input layer to a model instance my_model:\n",
        "\n",
        "```python\n",
        "my_model.add(my_input)\n",
        "```\n",
        "\n",
        "* The following code prints a useful summary of a model instance my_model:\n",
        "\n",
        "```python\n",
        "print(my_model.summary())\n",
        "```\n",
        "\n",
        "As you can see, the summary shows that the total number of parameters is 0. \n",
        "This shows you that the input layer has no trainable parameters and is just a placeholder for data."
      ],
      "metadata": {
        "id": "U8u6xFAJyxjJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#### EXERCISE 5 - Neural network model - Input Layer ####\n",
        "\n",
        "##### Neural network model: input layer Example\n",
        "\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "\n",
        "def design_model(features):\n",
        "  model = Sequential(name = \"my_first_model\")\n",
        "  #your code here\n",
        "  # In the design_model() function, create a variable called num_features and \n",
        "  # assign it the number of columns in the features DataFrame using the .shape property\n",
        "\n",
        "  ## get the number of features/dimensions in the data\n",
        "  num_features = features.shape[1]\n",
        "\n",
        "  # In the design_model() function:\n",
        "  # create a variable called input. assign input an instance of InputLayer. \n",
        "  # set the first dimension of the input_shape parameter equal to num_features\n",
        "\n",
        "  ## Notice that the input_shape parameter has to have its first dimension equal\n",
        "  ## to the number of features in the data. You don’t need to specify the second\n",
        "  #  dimension: the number of samples or batch size.\n",
        "  input = layers.InputLayer(input_shape=(num_features,))\n",
        "\n",
        "  # The following code adds this input layer to a model instance my_model:\n",
        "  model.add(input)\n",
        "\n",
        "  return model\n",
        "\n",
        "\n",
        "# dataset = pd.read_csv('insurance.csv') #load the dataset\n",
        "features = dataset.iloc[:,0:6] #choose first 7 columns as features\n",
        "labels = dataset.iloc[:,-1] #choose the final column for prediction\n",
        "\n",
        "# one-hot encoding for categorical variables\n",
        "features = pd.get_dummies(features)\n",
        "\n",
        "# split the data into training and test data\n",
        "features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size=0.33, random_state=42) \n",
        "\n",
        "# standardize\n",
        "## ColumnTransformer Applies transformers to columns of an array or pandas DataFrame.\n",
        "## This estimator allows different columns or column subsets of the input\n",
        "## to be transformed separately and the features generated by each transformer\n",
        "## will be concatenated to form a single feature space.\n",
        "ct = ColumnTransformer([('standardize', StandardScaler(), ['age', 'bmi', 'children'])], remainder='passthrough')\n",
        "features_train = ct.fit_transform(features_train)\n",
        "features_test = ct.transform(features_test)\n",
        "\n",
        "# Invoke the function for our model design\n",
        "model = design_model(features_train)\n",
        "\n",
        "## Use the .summary() method to print the summary of the model instance model.\n",
        "print(model.summary())\n",
        "\n",
        "# As you can see, the summary shows that the total number of parameters is 0. \n",
        "# This shows you that the input layer has no trainable parameters and is \n",
        "# just a placeholder for data."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O3z-Iol9ZD7w",
        "outputId": "3c424da4-d6df-48ca-e187-c8ed5ab2d810"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"my_first_model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            "=================================================================\n",
            "Total params: 0\n",
            "Trainable params: 0\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# THEORY 6 - Neural network model: output layer ####\n",
        "\n",
        "## Neural network model: output layer\n",
        "\n",
        "* The **output layer** shape depends on your task. In the case of regression, we need one output for each sample. For example, if your data has 100 samples, you would expect your output to be a vector with 100 entries - a numerical prediction for each sample.\n",
        "\n",
        "* In our case, we are doing regression and wish to predict one number for each data point: the medical cost billed by health insurance indicated in the  charges column in our data. Hence, our output layer has only one neuron.\n",
        "\n",
        "* The following command adds a layer with one neuron to a model instance my_model:\n",
        "\n",
        "```python\n",
        "from tensorflow.keras.layers import Dense\n",
        "my_model.add(Dense(1))\n",
        "```\n",
        "\n",
        "* Notice that you don’t need to specify the input shape of this layer since Tensorflow with Keras can automatically infer its shape from the previous layer.\n"
      ],
      "metadata": {
        "id": "LC_thsABzXC3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#### EXERCISE 6 - Neural network model: output layer ####\n",
        "##### Neural network model: output layer Example\n",
        "\n",
        "# create and add an output layer to the model instance model as an instance of \n",
        "from tensorflow.keras.layers import Dense\n",
        "model.add(Dense(1))"
      ],
      "metadata": {
        "id": "fRb0J-a0eK_e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## -> THEORY 7 - Neural network model: hidden layers ####\n",
        "\n",
        "So far we have added one input layer and one output layer to our model. If you think about it, our model currently represents a linear regression. \n",
        "\n",
        "\\\n",
        "\n",
        "To capture more complex or non-linear interactions among the inputs and outputs neural networks, we’ll need to incorporate hidden layers\n",
        "\n",
        "```python\n",
        "from tensorflow.keras.layers import Dense\n",
        "my_model.add(Dense(64, activation='relu'))\n",
        "```\n",
        "\n",
        "We chose 64 (2^6) to be the number of neurons since it makes optimization \n",
        "more efficient due to the binary nature of computation.\n",
        "\n",
        "\\\n",
        "\n",
        "### ACTIVATION FUNCTION\n",
        "\n",
        "With the activation parameter, we specify which activation function we want to have in the output of our hidden layer. There are a number of activation functions such as softmax, sigmoid, but ReLU (relu) (Rectified Linear Unit) is very effective in many applications and we’ll use it here.\n",
        "\n",
        "\\\n",
        "\n",
        "Adding more layers to a neural network naturally increases the number of parameters to be tuned. !!With every layer, there are associated weight and bias vectors.\n",
        "\n",
        "\\\n",
        "\n",
        "In following diagram below we show the size of parameter vectors with each \n",
        "layer. In our case, the 1st layer’s weight matrix (red) has shape (11, 64) \n",
        "because we feed 11 features to 64 hidden neurons. The output layer (purple) \n",
        "has the weight matrix of shape (64, 1) because we have 64 input units and 1 neuron in the final layer."
      ],
      "metadata": {
        "id": "FsXcTYtOyXhm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#### EXERCISE 7 - Neural network model: hidden layers ####\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import InputLayer\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "\n",
        "def design_model(features):\n",
        "  model = Sequential(name = \"my_first_model\")\n",
        "\n",
        "  # input_shape parameter has to have its first dimension equal\n",
        "  # to the number of features in the data.\n",
        "  input = InputLayer(input_shape=(features.shape[1],))\n",
        "\n",
        "  #add the input layer\n",
        "  model.add(input)\n",
        "\n",
        "  # add a new hidden layer to the model instance model with the following parameters:\n",
        "  # 128 hidden units a relu activation function\n",
        "  model.add(Dense(128, activation='relu'))\n",
        "\n",
        "  #adding an output layer to our model\n",
        "  model.add(Dense(1)) \n",
        "  return model\n",
        "\n",
        "#dataset = pd.read_csv('insurance.csv') #load the dataset\n",
        "features = dataset.iloc[:,0:6] #choose first 7 columns as features\n",
        "labels = dataset.iloc[:,-1] #choose the final column for prediction\n",
        "\n",
        "features = pd.get_dummies(features) #one-hot encoding for categorical variables\n",
        "\n",
        "#split the data into training and test data\n",
        "features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size=0.33, random_state=42) \n",
        " \n",
        "#standardize\n",
        "ct = ColumnTransformer([('standardize', StandardScaler(), ['age', 'bmi', 'children'])], remainder='passthrough')\n",
        "features_train = ct.fit_transform(features_train)\n",
        "features_test = ct.transform(features_test)\n",
        "\n",
        "#invoke the function for our model design\n",
        "model = design_model(features_train)\n",
        "\n",
        "#print the model summary here\n",
        "print(model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zqGTLTEk6RTe",
        "outputId": "a20fac1f-8f12-430e-a150-65ac6e3de955"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"my_first_model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_5 (Dense)             (None, 128)               1536      \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,665\n",
            "Trainable params: 1,665\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## -> THEORY 8 - OPTIMIZERS\n",
        "\n",
        "As we mentioned, our goal is for the network to effectively adjust its weights\n",
        "or parameters in order to reach the best performance. Keras offers a variety of optimizers such as SGD (Stochastic Gradient Descent optimizer), Adam, RMSprop, and others.\n",
        "\n",
        "\\\n",
        "\n",
        "We’ll start by introducing the Adam optimizer:\n",
        "\n",
        "```python\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "opt = Adam(learning_rate=0.01)\n",
        "```\n",
        "\n",
        "The **learning rate determines how big of jumps the optimizer makes in the \n",
        "parameter space** (weights and bias) and it is considered a hyperparameter that can be also tuned. While model parameters are the ones that the model uses to make predictions, hyperparameters determine the learning process (learning rate,number of iterations, optimizer type).\n",
        "\n",
        "\\\n",
        "\n",
        "If the learning rate is set too high, the optimizer will make large jumps and \n",
        "possibly miss the solution. On the other hand, if set too low, the learning \n",
        "process is too slow and might not converge to a desirable solution with the \n",
        "allotted time. Here we’ll use a value of 0.01, which is often used.\n",
        "\n",
        "\\\n",
        "\n",
        "Once the optimizer algorithm is chosen, a model instance my_model is compiled \n",
        "with the following code:\n",
        "\n",
        "```python\n",
        "my_model.compile(loss='mse',  metrics=['mae'], optimizer=opt)\n",
        "```\n",
        "\n",
        "**loss** denotes the measure of learning success and the lower the loss the better the performance. In the case of regression, the most often used loss function is the **Mean Squared Error** mse (the average squared difference between the estimated values and the actual value).\n",
        "\n",
        "\\\n",
        "\n",
        "Additionally, we want to observe the progress of the **Mean Absolute Error** (mae) while training the model because MAE can give us a better idea than mse on how far off we are from the true values in the units we are predicting. \n",
        "\n",
        "In our case, we are predicting charge in dollars and MAE will tell us how many dollars we’re off, on average, from the actual values as the network is being trained."
      ],
      "metadata": {
        "id": "u_8rgloMxYE3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#### EXERCISE 8 - OPTIMIZERS ####\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import InputLayer\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "\n",
        "def design_model(features):\n",
        "  model = Sequential(name = \"my_first_model\")\n",
        "  input = InputLayer(input_shape=(features.shape[1],))\n",
        "   #add an input layer\n",
        "  model.add(input)\n",
        "  #add a hidden layer with 128 neurons\n",
        "  model.add(Dense(128, activation='relu')) \n",
        "  #add an output layer\n",
        "  model.add(Dense(1)) \n",
        "  #your code here\n",
        "  opt = Adam(learning_rate=0.01)\n",
        "  model.compile(loss='mse', metrics=['mae'], optimizer=opt)\n",
        "  return model\n",
        "\n",
        "\n",
        "#dataset = pd.read_csv('insurance.csv') #load the dataset\n",
        "features = dataset.iloc[:,0:6] #choose first 7 columns as features\n",
        "labels = dataset.iloc[:,-1] #choose the final column for prediction\n",
        "\n",
        "features = pd.get_dummies(features) #one-hot encoding for categorical variables\n",
        "features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size=0.33, random_state=42) #split the data into training and test data\n",
        " \n",
        "#standardize\n",
        "ct = ColumnTransformer([('standardize', StandardScaler(), ['age', 'bmi', 'children'])], remainder='passthrough')\n",
        "features_train = ct.fit_transform(features_train)\n",
        "features_test = ct.transform(features_test)\n",
        "\n",
        "#invoke the function for our model design\n",
        "model = design_model(features_train)\n",
        "print(model.summary())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yau4cAoiziUn",
        "outputId": "0eb678c7-b11c-4f7f-9e3f-2dae3547bc4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"my_first_model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_7 (Dense)             (None, 128)               1536      \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,665\n",
            "Trainable params: 1,665\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## -> THEORY 9 - Training and evaluating the model\n",
        "\n",
        "Now that we built the model we are ready to train the model using the training data.\n",
        "\n",
        "\\\n",
        "\n",
        "The following command trains a model instance my_model using training data my_data and training labels my_labels :\n",
        "\n",
        "```python\n",
        "my_model.fit(my_data, my_labels, epochs=50, batch_size=3, verbose=1)\n",
        "```\n",
        "\n",
        "model.fit() takes the following parameters:\n",
        "* my_data is the training data set.\n",
        "* my_labels are true labels for the training data points.\n",
        "* epochs refers to the number of cycles through the full training dataset. Since training of neural networks is an iterative process, you need multiple passes through data. Here we chose 50 epochs, but how do you pick a number of epochs? Well, it is hard to give one answer since it depends on your dataset. Amongst others, this is a hyperparameter that can be tuned — which we’ll cover later.\n",
        "* batch_size is the number of data points to work through before updating the model parameters. It is also a hyperparameter that can be tuned.\n",
        "* verbose = 1 will show you the progress bar of the training.\n",
        "\n",
        "\n",
        "When the training is finalized, we use the trained model to predict values for samples that the training procedure haven’t seen: the test set.\n",
        "\n",
        "\\\n",
        "\n",
        "The following commands evaluates the model instance my_model using the test data my_data and test labels my_labels:\n",
        "\n",
        "```python\n",
        "val_mse, val_mae = my_model.evaluate(my_data, my_labels, verbose = 0)\n",
        "```\n",
        "\n",
        "So what is the final result? We should get ~$3884.21. This means that on average we’re off with our prediction by around 3800 dollars. Is that a good result or a bad result?\n",
        "\n",
        "\\\n",
        "\n",
        "Often you need an expert or domain knowledge to decide this. What is an acceptable error for the application? Is $3800 a big error when deciding on insurance charges? Can you do better and how? As you see, the process doesn’t stop here."
      ],
      "metadata": {
        "id": "7InVBAjt1Wmp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#### EXERCISE 9 - Training and evaluating the model ####\n",
        "\n",
        "import pandas as pd\n",
        "import tensorflow\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import InputLayer\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "tensorflow.random.set_seed(35) #for the reproducibility of results\n",
        "\n",
        "def design_model(features):\n",
        "  model = Sequential(name = \"my_first_model\")\n",
        "  #without hard-coding\n",
        "  input = InputLayer(input_shape=(features.shape[1],)) \n",
        "  #add the input layer\n",
        "  model.add(input) \n",
        "  #add a hidden layer with 128 neurons\n",
        "  model.add(Dense(128, activation='relu')) \n",
        "  #add an output layer to our model\n",
        "  model.add(Dense(1)) \n",
        "  opt = Adam(learning_rate=0.1)\n",
        "  model.compile(loss='mse',  metrics=['mae'], optimizer=opt)\n",
        "  return model\n",
        "\n",
        "#dataset = pd.read_csv('insurance.csv') #load the dataset\n",
        "features = dataset.iloc[:,0:6] #choose first 7 columns as features\n",
        "labels = dataset.iloc[:,-1] #choose the final column for prediction\n",
        "\n",
        "features = pd.get_dummies(features) #one-hot encoding for categorical variables\n",
        "features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size=0.33, random_state=42) #split the data into training and test data\n",
        " \n",
        "# standardize\n",
        "ct = ColumnTransformer([('standardize', StandardScaler(), ['age', 'bmi', 'children'])], remainder='passthrough')\n",
        "features_train = ct.fit_transform(features_train)\n",
        "features_test = ct.transform(features_test)\n",
        "\n",
        "# invoke the function for our model design\n",
        "model = design_model(features_train)\n",
        "print(model.summary())\n",
        "\n",
        "# fit the model using 40 epochs and batch size 1\n",
        "model.fit(features_train, labels_train, epochs=40, batch_size=1, verbose=0)\n",
        "\n",
        "# evaluate the model on the test data\n",
        "val_mse, val_mae = model.evaluate(features_test, labels_test, verbose=1)\n",
        "\n",
        "print(\"MAE: \", val_mae)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yP7qoqpj2kqe",
        "outputId": "f0c1d771-33a5-4cf9-b1d1-299399fde279"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"my_first_model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_9 (Dense)             (None, 128)               1536      \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,665\n",
            "Trainable params: 1,665\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "14/14 [==============================] - 0s 2ms/step - loss: 21536414.0000 - mae: 2490.1587\n",
            "MAE:  2490.15869140625\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "1_Neural_Network_StepByStep.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOc/Lza7JDwwsAD+TwXBgWK",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}