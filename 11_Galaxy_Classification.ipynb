{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "11_Galaxy_Classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNwgkmXCkPEglXw+baVJk8h",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rcarrata/deeplearning_tf_examples/blob/master/11_Galaxy_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classifying Galaxies\n",
        "\n",
        "## Classifying Galaxies Using Convolutional Neural Networks\n",
        "Around the clock, telescopes affixed to orbital satellites and ground-based observatories are taking millions of pictures of millions upon millions of celestial bodies. These data, of stars, planets and galaxies provide an invaluable resource to astronomers.\n",
        "\n",
        "However, there is a bottleneck: until the data is annotated, it’s incredibly difficult for scientists to put it to good use. Additionally, scientists are usually interested in subsets of the data, like galaxies with unique characteristics.\n",
        "\n",
        "In this project, you will build a neural network to classify deep-space galaxies. You will be using image data curated by Galaxy Zoo, a crowd-sourced project devoted to annotating galaxies in support of scientific discovery.\n",
        "\n",
        "You will identify “odd” properties of galaxies. The data falls into four classes:\n",
        "\n",
        "* [1,0,0,0] - Galaxies with no identifying characteristics.\n",
        "* [0,1,0,0] - Galaxies with rings.\n",
        "* [0,0,1,0] - Galactic mergers.\n",
        "* [0,0,0,1] - “Other,” Irregular celestial bodies.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "q3vjV7Fjr7Ii"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Steps \n",
        "\n",
        "1. Because the dataset comprises over one thousand images, you’ll use a custom function, load_galaxy_data() to load the compressed data files into the Codecademy learning environment as NumPy arrays. Take a look at the shape of the data.\n",
        "\n",
        "  Use .shape to print the dimensions of the input_data and labels.\n",
        "\n",
        "  What does the last dimension of the data indicate about the image data? What does the last dimension of the labels indicate about the labels?\n",
        "\n",
        "  Use print(input_data.shape) and print(labels.shape).\n",
        "\n",
        "  Because the last dimension of the data is 3, you know that the image data is RGB/in color. Because the last dimension of the labels is 4, and there are four classes, you know that the labels are one-hot vectors. For example, [1,0,0,0] → Normal galaxy.\n",
        "\n",
        "2. Next, divide the data into training and validation data, using sklearn’s train_test_split() function.\n",
        "\n",
        "* Set the test_size argument to be 0.20.\n",
        "* Shuffle the data.\n",
        "* Set the random_state to be 222.\n",
        "* Set stratify=labels. This ensures that ratios of galaxies in your testing data will be the same as in the original dataset.\n",
        "\n",
        "  Your code should look something like this:\n",
        "\n",
        "  ```\n",
        "  x_train, x_valid, y_train, y_valid = train_test_split(input_data, labels, test_size=0.20, stratify=labels, shuffle=True, random_state=222)\n",
        "  ```\n",
        "\n",
        "3. Now, it’s time to preprocess the input.\n",
        "\n",
        "  Define an ImageDataGenerator, and configure it so that the object will normalize the pixels using the rescale parameter.\n",
        "\n",
        "  You can do this with the following line of code:\n",
        "\n",
        "  ```\n",
        "  data_generator = ImageDataGenerator(rescale=1./255)\n",
        "  ```\n",
        "\n",
        "4. Next, create two NumpyArrayIterators using the .flow(x,y,batch_size=?) method. We recommend using a batch size of 5. Significantly larger batch sizes may cause memory issues on the Codecademy platform.\n",
        "\n",
        "  Create a training data iterator by calling .flow() on your training data and labels.\n",
        "\n",
        "  Create a validation data iterator by calling .flow() on your training data and labels.\n",
        "\n",
        "  Your code should use the .flow() method like this:\n",
        "\n",
        "  ```\n",
        "  training_iterator = data_generator.flow(x_train, y_train,batch_size=5)\n",
        "  validation_iterator = data_generator.flow(x_valid, y_valid, batch_size=5)\n",
        "  ```\n",
        "\n",
        "5. Next, build your model, starting with the input shape and output layer.\n",
        "\n",
        "  Create a tf.keras.Sequential model named model.\n",
        "\n",
        "  Add a tf.keras.Input layer. Refer back to the shape of the data. What should the input shape be?\n",
        "\n",
        "  Add a tf.keras.layers.Dense layer as your output layer. Make sure that it outputs 4 features, for the four classes (“Normal”,”Ringed”,”Merger”,”Other”).\n",
        "\n",
        "  Remember to use a softmax activation on this final layer.\n",
        "\n",
        "  Your input shape should be (128,128,3). This is because the images are 128 pixels tall, 128 pixels wide, and have 3 channels: Red, Green, and Blue.\n",
        "\n",
        "  Your solution should add the layers to a Sequential model:\n",
        "\n",
        "  ```\n",
        "  model = tf.keras.Sequential()\n",
        "  model.add(tf.keras.Input(shape=(128, 128, 3)))\n",
        "  model.add(tf.keras.layers.Dense(4,activation=\"softmax\"))\n",
        "  ```\n",
        "\n",
        "6. Before you finish designing your architecture, compile your model with an optimizer, loss, and metrics.\n",
        "\n",
        "  Use model.compile(optimizer=?,loss=?, metrics=[?,?]) to compile your model.\n",
        "\n",
        "  * Use tf.keras.optimizers.Adam with a learning_rate of 0.001.\n",
        "\n",
        "  * Because the labels are one-hot categories, use tf.keras.losses.CategoricalCrossentropy() as your loss.\n",
        "\n",
        "  * Set [tf.keras.metrics.CategoricalAccuracy(),tf.keras.metrics.AUC()] as your metrics.\n",
        "\n",
        "  Your code for compiling the model should look like this:\n",
        "\n",
        "  ```\n",
        "  model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "    loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "    metrics=[tf.keras.metrics.CategoricalAccuracy(),tf.keras.metrics.AUC()])\n",
        "  ```\n",
        "\n",
        "7. Now, let’s go back and finish fleshing out your architecture. An architecture that works well on this task is two convolutional layers, interspersed with max pooling layers, followed by two dense layers:\n",
        "\n",
        "  * Conv2D: 8 filters, each 3x3 with strides of 2\n",
        "  * MaxPooling2D: pool_size=(2, 2), strides=2\n",
        "  * Conv2D: 8 filters, each 3x3 with strides of 2\n",
        "  * MaxPooling2D: pool_size=(2, 2), strides=2\n",
        "  * Flatten Layer\n",
        "  * Hidden Dense Layer with 16 hidden units\n",
        "  * Output Dense Layer\n",
        "\n",
        "  Try coding up this architecture yourself, using:\n",
        "\n",
        "  * tf.keras.layers.Conv2D\n",
        "  * tf.keras.layers.MaxPooling2D\n",
        "  * tf.keras.layers.Flatten()\n",
        "  * tf.keras.layers.Dense()\n",
        "\n",
        "  Don’t forget to use “relu” activations for Dense and Conv2D hidden layers!\n",
        "\n",
        "  The full architecture of the model can be defined like this:\n",
        "\n",
        "  ```\n",
        "  model = tf.keras.Sequential()\n",
        "  model.add(tf.keras.Input(shape=(128, 128, 3)))\n",
        "  model.add(tf.keras.layers.Conv2D(8, 3, strides=2, activation=\"relu\")) \n",
        "  model.add(tf.keras.layers.MaxPooling2D(\n",
        "    pool_size=(2, 2), strides=(2,2)))\n",
        "  model.add(tf.keras.layers.Conv2D(8, 3, strides=2, activation=\"relu\")) \n",
        "  model.add(tf.keras.layers.MaxPooling2D(\n",
        "    pool_size=(2,2), strides=(2,2)))\n",
        "  model.add(tf.keras.layers.Flatten())\n",
        "  model.add(tf.keras.layers.Dense(16, activation=\"relu\"))\n",
        "  model.add(tf.keras.layers.Dense(4, activation=\"softmax\"))\n",
        "  ```\n",
        "\n",
        "8. At this point, your model should have 7,164 parameters. Use model.summary() to confirm this.\n",
        "\n",
        "9. Use model.fit(...) to train your model.\n",
        "\n",
        "  * The first argument should be your training iterator.\n",
        "\n",
        "  * Set steps_per_epoch to be the length of your training data, divided by your batch size.\n",
        "\n",
        "  * Set epochs to be 8.\n",
        "\n",
        "  * Set validation_data to be your validation iterator.\n",
        "\n",
        "  * Set validation_steps to be the length of your validation data, divided by your batch size.\n",
        "\n",
        "  ```\n",
        "  model.fit(\n",
        "        training_iterator,\n",
        "        steps_per_epoch=len(x_train)/5,\n",
        "        epochs=8,\n",
        "        validation_data=validation_iterator,\n",
        "        validation_steps=len(x_valid)/5)\n",
        "  ```\n",
        "\n",
        "10. Now you can run your code to train the model. Training may take a minute or two. After training for twelve epochs, your model’s accuracy should be around 0.60-0.70, and your AUC should fall into the 0.80-0.90 range!\n",
        "\n",
        "  What do these results mean?\n",
        "\n",
        "  Your accuracy tells you that your model assigns the highest probability to the correct class more than 60% of the time. For a classification task with over four classes, this is no small feat: a random baseline model would achieve only ~25% accuracy on the dataset. Your AUC tells you that for a random galaxy, there is more than an 80% chance your model would assign a higher probability to a true class than to a false one.\n",
        "\n",
        "11. You have successfully trained a Convolutional Neural Network to classify galaxies.\n",
        "\n",
        "  Think you can do even better? If you would like, try tweaking your architecture. Can you find a better set of hyperparameters? Make sure to watch your parameter count: it’s easy to accidentally create a model with more than tens of thousands of parameters, which could overfit to your relatively small dataset (or crash the Learning Environment).\n",
        "\n",
        "  Note that scores will fluctuate a bit, depending on how the weights are randomly initialized.\n",
        "\n",
        "  Here are a few parameters that you could consider tweaking:\n",
        "\n",
        "  * learning rate\n",
        "  * number of convolutional layers\n",
        "  * number of filters, strides, and padding type per layer\n",
        "  * stride and pool_size of max pooling layers\n",
        "  * size of hidden linear layers\n",
        "\n",
        "\n",
        "12. BONUS Want to visualize how your convolutional neural network processes images?\n",
        "\n",
        "  Take a look at visualize.py. It contains a function, visualize_activations().\n",
        "\n",
        "  This function loads in sample data, uses your model to make predictions, and then saves the feature maps from each convolutional layer. These feature maps showcase the activations of each filter as they are convolved across the input.\n",
        "\n",
        "  Try importing this function by adding the following to the end of train.py:\n",
        "\n",
        "  ```\n",
        "  from visualize import visualize_activations\n",
        "  visualize_activations(model,YOUR_VALIDATION_ITERATOR)\n",
        "  ```\n",
        "\n",
        "  And then replace YOUR_VALIDATION_ITERATOR with the NumpyIterator you defined in task four.\n",
        "\n",
        "  You are not required to understand the visualization code. However, the hint provides a summary.\n",
        "\n",
        "\n",
        "  visualize_results takes your Keras model and the validation iterator and does the following:\n",
        "\n",
        "  * It loads in a sample batch of data using your validation iterator.\n",
        "\n",
        "  * It uses model.predict() to generate predictions for the first sample images.\n",
        "\n",
        "  * Next, it compares those predictions with the true labels and prints the result.\n",
        "\n",
        "  * It then saves the image and the feature maps for each convolutional layer using matplotlib."
      ],
      "metadata": {
        "id": "hPBndEh5tShr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train.py\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from visualize import visualize_activations\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from utils import load_galaxy_data\n",
        "\n",
        "import app\n",
        "\n",
        "\n",
        "input_data, labels = load_galaxy_data()\n",
        "\n",
        "print(input_data.shape)\n",
        "print(labels.shape)\n",
        "\n",
        "x_train, x_valid, y_train, y_valid = train_test_split(\n",
        "    input_data,\n",
        "    labels,\n",
        "    test_size = 0.20,\n",
        "    shuffle=True,\n",
        "    random_state=222,\n",
        "    stratify=labels)\n",
        "\n",
        "validation_data_generator = ImageDataGenerator(\n",
        "  rescale = 1./255\n",
        ")\n",
        "\n",
        "training_iterator = validation_data_generator.flow(x_train, y_train, batch_size=5)\n",
        "\n",
        "validation_iterator = validation_data_generator.flow(x_valid,y_valid,batch_size=5)\n",
        "\n",
        "model = tf.keras.Sequential()\n",
        "\n",
        "# Input Layer\n",
        "model.add(tf.keras.Input(shape=(128,128,3)))\n",
        "\n",
        "model.add(tf.keras.layers.Conv2D(8, 3, strides=2, activation=\"relu\")) \n",
        "model.add(tf.keras.layers.MaxPooling2D(\n",
        "    pool_size=(2, 2), strides=(2,2)))\n",
        "model.add(tf.keras.layers.Conv2D(8, 3, strides=2, activation=\"relu\")) \n",
        "model.add(tf.keras.layers.MaxPooling2D(\n",
        "    pool_size=(2,2), strides=(2,2)))\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.Dense(16, activation=\"relu\"))\n",
        "\n",
        "# Output Layer\n",
        "model.add(tf.keras.layers.Dense(4,activation=\"softmax\"))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "    loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "    metrics=[tf.keras.metrics.CategoricalAccuracy(),tf.keras.metrics.AUC()]\n",
        ")\n",
        "\n",
        "model.fit(\n",
        "  training_iterator,\n",
        "  steps_per_epoch=len(x_train)/5,\n",
        "  epochs=8,\n",
        "  validation_data=validation_iterator,\n",
        "  validation_steps=len(x_valid)/5\n",
        ")\n",
        "\n",
        "visualize_activations(model,validation_iterator)\n"
      ],
      "metadata": {
        "id": "pm4AZbMYFHFB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize.py\n",
        "\n",
        "import tensorflow as tf\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "#Visualizes convolutional layer activations\n",
        "def visualize_activations(model, validation_iterator):\n",
        "\n",
        "  #A keras model that will output our previous model's activations for each convolutional layer:\n",
        "  activation_extractor = tf.keras.Model(inputs=model.inputs, outputs=[layer.output for layer in model.layers if \"conv2d\" in layer.name])\n",
        "\n",
        "  #Take matplotlib frame and remove axes.\n",
        "  def clean_plot(plot):\n",
        "    plot.axes.get_xaxis().set_visible(False)\n",
        "    plot.axes.get_yaxis().set_visible(False)\n",
        "\n",
        "  #Dict mapping from class numbers to string labels:\n",
        "  class_names = {0:\"Regular\",1:\"Ringed\",2:\"Merger\",3:\"Other\"}\n",
        "\n",
        "  #Loads a sample batch of data\n",
        "  sample_batch_input,sample_labels = validation_iterator.next()\n",
        " \n",
        "  #Grabs the first five images\n",
        "  sample_batch_input = sample_batch_input[:5]\n",
        "  sample_labels = sample_labels[:5]\n",
        "\n",
        "  #Makes predictions using model.predict(x)\n",
        "  sample_predictions = model.predict(sample_batch_input)\n",
        "\n",
        "  #Iterate of images, predictions, and true labels\n",
        "  for i,(image, prediction, label) in enumerate(zip(sample_batch_input, sample_predictions, sample_labels)):\n",
        "\n",
        "    image_name = \"Galaxy_{}\".format(i)\n",
        "\n",
        "    #Gets predicted class with highest probability\n",
        "\n",
        "    predicted_class = tf.argmax(prediction).numpy()\n",
        "\n",
        "    #Gets correct label\n",
        "    actual_class = tf.argmax(label).numpy()\n",
        "\n",
        "    print(image_name)\n",
        "    print(\"\\tModel prediction: {}\".format(prediction))\n",
        "    print(\"\\tTrue label: {} ({})\".format(class_names[actual_class], actual_class))\n",
        "    print(\"\\tCorrect:\", predicted_class == actual_class)\n",
        "\n",
        "    #Saves image file using matplotlib\n",
        "    sample_image = image\n",
        "    clean_plot(plt.imshow(sample_image))\n",
        "\n",
        "    plt.title(image_name+\" Predicted: {}, Actual: {}\".format(class_names[predicted_class], class_names[actual_class]))\n",
        "    plt.savefig('static/images/'+image_name+\".png\")\n",
        "    model_layer_output = activation_extractor(tf.expand_dims(sample_image,0))\n",
        "    \n",
        "    plt.clf()\n",
        "\n",
        "    #Iterates over each layer output\n",
        "    for l_num,output_data in enumerate(model_layer_output):\n",
        "\n",
        "      #Creates a subplot for each filter\n",
        "      fig, axs = plt.subplots(1, output_data.shape[-1])\n",
        "      \n",
        "      #For each filter\n",
        "      for i in range(output_data.shape[-1]):\n",
        "\n",
        "        #Plots the filter's activations\n",
        "        \n",
        "        clean_plot(axs[i].imshow(output_data[0][:, :, i], cmap=\"gray\"))\n",
        "      plt.suptitle(image_name+\" Conv {}\".format(l_num),y=0.6)\n",
        "      plt.savefig('static/images/' + image_name+ \"Conv{}.png\".format(l_num))\n",
        "      plt.clf()"
      ],
      "metadata": {
        "id": "WidH5UhIr7V0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# utils.py\n",
        "\n",
        "import requests\n",
        "import io\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "#Loads data from url\n",
        "def make_request(url):\n",
        "    print(\"Requesting data from {}...\".format(url))\n",
        "    response = requests.get('https://content.codecademy.com/courses/deeplearning-with-tensorflow/'+url)\n",
        "    response.raise_for_status()\n",
        "    response_data = io.BytesIO(response.content)\n",
        "    return response_data\n",
        "    \n",
        "#Loads galaxy data\n",
        "def load_galaxy_data():\n",
        "  \n",
        "  #If cached file not found, loads data from url\n",
        "  if not os.path.isfile('./cached_data.npz'):\n",
        "     response_data = make_request(url='galaxydata.npz')\n",
        "\n",
        "     with open(\"cached_data.npz\",\"wb\") as save_file:\n",
        "      save_file.write(response_data.read())\n",
        " \n",
        "  #Load data using NumPy\n",
        "  data = np.load('cached_data.npz')\n",
        "\n",
        "  print(\"Successfully loaded galaxy data!\")\n",
        "  \n",
        "  return data[\"data\"],data[\"labels\"]"
      ],
      "metadata": {
        "id": "BX-Cy6CJsWfn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# app.py\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from flask import Flask, render_template\n",
        "from flask_sqlalchemy import SQLAlchemy\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "#some routing for displaying the home page\n",
        "@app.route('/')\n",
        "@app.route('/home')\n",
        "def plot_graph():\n",
        "  return render_template('plt_tmpl.html', name = \"Visualizations Created in Task 12\", \n",
        "                         url1 ='static/images/Galaxy_0Conv0.png', \n",
        "                         url2='static/images/Galaxy_0Conv1.png', \n",
        "                         url3='static/images/Galaxy_0.png', \n",
        "                         url4 ='static/images/Galaxy_1Conv0.png', \n",
        "                         url5='static/images/Galaxy_1Conv1.png', \n",
        "                         rl6='static/images/Galaxy_1.png',\n",
        "                         url7 ='static/images/Galaxy_2Conv0.png', \n",
        "                         url8='static/images/Galaxy_2Conv1.png', \n",
        "                         url9='static/images/Galaxy_2.png', \n",
        "                         url10 ='static/images/Galaxy_3Conv0.png', \n",
        "                         url11='static/images/Galaxy_3Conv1.png', \n",
        "                         url12='static/images/Galaxy_3.png', \n",
        "                         url13 ='static/images/Galaxy_4Conv0.png', \n",
        "                         url14='static/images/Galaxy_4Conv1.png', \n",
        "                         url15='static/images/Galaxy_4.png')"
      ],
      "metadata": {
        "id": "cOv_qIZssZiD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "uS_-LJeksmPx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}